{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualization_WO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDWcVLr0IcCRE4A49N2X5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianbentz/Workshop_DGfS2022/blob/main/Code/Application2/Visualization_WO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Order Entropy Visualization\n",
        "\n",
        "Author: Chris Bentz\n",
        "\n",
        "Date: 18/02/2022"
      ],
      "metadata": {
        "id": "lQoQ1xLgXilI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries\n",
        "\n",
        "Some packages are already pre-installed on jupyter, but some need to be installed. Run this code to make sure that the packages/libraries needed to run this code are installed.\n"
      ],
      "metadata": {
        "id": "G4fygXgoXwpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"ggrepel\")"
      ],
      "metadata": {
        "id": "TK0QEf6UX7qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Libraries\n",
        "If the libraries are not installed yet, you need to install them using, for example, the command: install.packages(\"ggplot2\")."
      ],
      "metadata": {
        "id": "h8Ik69zVXsxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OqUO4q_JWbsq"
      },
      "outputs": [],
      "source": [
        "library(ggplot2)\n",
        "library(ggrepel)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "Load file with ML estimated word order entropies and unigram orthographic word entropies across ca. 1000 languages."
      ],
      "metadata": {
        "id": "k7--3SLSYHcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.est.wo <- read.csv(file = \"/content/results/wordorder_tokens.csv\")\n",
        "head(h.est.wo)"
      ],
      "metadata": {
        "id": "ET6d6gv0YMKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "Use only data from Parallel Bible Corpus (this also removes NAs). Also, languages might be included/excluded according to how many sentences they have in the word order variable."
      ],
      "metadata": {
        "id": "X7sBDxUhYtJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use PBC\n",
        "h.est.wo.clean <- h.est.wo[h.est.wo$corpus == \"PBC\", ]\n",
        "# only use languages with more than x sentences (in the word order variable)\n",
        "h.est.wo.clean <- h.est.wo.clean[h.est.wo.clean$Num_Sentences > 10, ]\n",
        "# check how many rows, i.e. languages are left\n",
        "nrow(h.est.wo.clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FDxtfz1dYvVU",
        "outputId": "635d28ea-c462-46d6-ef15-1c081d4b5fb4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 904"
            ],
            "text/latex": "904",
            "text/markdown": "904",
            "text/html": [
              "904"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scatterplots\n",
        "Create scatterplots with entropy estimations on the x-axis and y-axis."
      ],
      "metadata": {
        "id": "Znnbvn4YY38s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.plot <- ggplot(h.est.wo.clean, aes(x = H_ML, y = H_SO)) + \n",
        "  geom_point(alpha = 0.8, size  = 1) +\n",
        "  geom_smooth(method = \"lm\") +\n",
        "  #geom_label_repel(aes(label = ISO), label.size = 0.2, size = 3) + \n",
        "  labs(x = \"Unigram Entropy for Words (ML Estimate)\", \n",
        "       y = \"Entropy of SO Order (ML Estimate)\")\n",
        "h.plot"
      ],
      "metadata": {
        "id": "oqn2Y6EhZD1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear model\n",
        "Fit a simple linear model which corresponds to the linear model (lm) smoother in the scatterplot."
      ],
      "metadata": {
        "id": "YNY_jtuMZ5NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model <- lm(H_SO~H_ML, data = h.est.wo.clean)\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "faypzlT2Z78l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safe Figures\n",
        "Safe complete figures to file."
      ],
      "metadata": {
        "id": "YtfmhSzgavhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggsave(\"/content/WordOrderEntropyPlot.pdf\", h.plot, dpi = 300, \n",
        "       scale = 1, device = cairo_pdf)"
      ],
      "metadata": {
        "id": "TyRX0XF4axq0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}