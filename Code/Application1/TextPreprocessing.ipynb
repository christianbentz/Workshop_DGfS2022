{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextPreprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Text Preprocessing\n",
        "\n",
        "Author: Chris Bentz\n",
        "\n",
        "Date: 18/02/2022"
      ],
      "metadata": {
        "id": "7MYyOJIvmFc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries\n",
        "Some packages are already pre-installed on jupyter, but some need to be installed. Run this code to make sure that the packages/libraries needed to run this code are installed."
      ],
      "metadata": {
        "id": "mCsUnX6El8TH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OskEO_2qPWkT"
      },
      "outputs": [],
      "source": [
        "install.packages(\"gsubfn\")\n",
        "install.packages(\"readr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries\n",
        "If the respective libraries are not installed yet, you need to install them using, for example, the command: install.packages(\"gsubfn\")"
      ],
      "metadata": {
        "id": "u1y4bt3jl51g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(gsubfn)\n",
        "library(readr)"
      ],
      "metadata": {
        "id": "7xrbBe-wPk0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List Files\n",
        "Create list with all the files which are about to be processed. The path needs to point to the exact location (i.e. folder) where all the raw text files are stored."
      ],
      "metadata": {
        "id": "JQynSYfunwcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# file list for udhr and voynich texts\n",
        "filelist <- list.files(path = \"/content/original\", \n",
        "                        recursive = T, full.names = T)\n",
        "# give the first six elements of the list by using the function head()                        \n",
        "head(filelist)\n",
        "# give the length of the list (i.e. number of file paths)\n",
        "length(filelist)"
      ],
      "metadata": {
        "id": "wTYi6F4yQGKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing\n",
        "The code below runs a for-loop through all the text files to remove meta-information, and split the text into individual UTF-8 characters. The output is then safed in the folder \"processed\".\n"
      ],
      "metadata": {
        "id": "3zyjtQ8MrXiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# capture starting time\n",
        "start.time <- Sys.time()\n",
        "\n",
        "# set a counter \n",
        "counter <- 0\n",
        "\n",
        "# use for-loop to run through all files\n",
        "for (file in filelist) { \n",
        "  # loading textfile (\"skip\" specifies the number of lines to skip, whereas\n",
        "  # nmax gives the max number of lines to read.)\n",
        "  textfile <- scan(file, what = \"char\", encoding = \"UTF-8\", \n",
        "                          sep = \"\\n\" , skip = 8, nmax = 100) \n",
        "  # remove tabs, parentheses, and further symbols that cause processing issues\n",
        "  textfile <- gsubfn(\".\", list(\"\\t\" = \"\", \"(\" = \"\", \")\" = \"\", \n",
        "                                \"]\" = \"\", \"[\" = \"\", \"}\" = \"\",  \n",
        "                                \"{\" = \"\", \"*\" = \"\", \"+\" = \"\"), textfile)\n",
        "  # remove line annotations marked by '<>'\n",
        "  textfile <- gsub(\"<.*>\", \"\", textfile) \n",
        "  # get filename\n",
        "  filename <- basename(file)\n",
        "  print(filename)\n",
        "  # split the textfile into individual utf-8 characters. \n",
        "  # The output of strsplit() is a list, so it needs to be \"unlisted\" \n",
        "  # to get a vector. Note that white spaces are counted as utf-8 characters.\n",
        "  chars <- unlist(strsplit(textfile, \"\"))\n",
        "  # remove white spaces from character vector\n",
        "  chars <- chars[chars != \" \"] \n",
        "  # remove NAs for vectors which are already shorter than n\n",
        "  chars <- chars[!is.na(chars)]\n",
        "  # print(head(chars)) \n",
        "  # write characters to file\n",
        "  output.file <- paste(\"/content/processed/\", filename, sep = \"\")\n",
        "  write_lines(chars, output.file, sep = \" \")\n",
        "  # counter\n",
        "  counter <- counter + 1\n",
        "  print(counter)\n",
        "}\n",
        "\n",
        "# get end time\n",
        "end.time <- Sys.time()\n",
        "end.time - start.time"
      ],
      "metadata": {
        "id": "0UKYonoUQGf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r6QQhzb_QGtm"
      }
    }
  ]
}