?write_lines()
knitr::opts_chunk$set(echo = TRUE)
file.list <- list.files(path = "~/Github/Workshop_DGfS2022/Data/processed",
recursive = T, full.names = T)
head(file.list)
length(file.list)
entropy.df <- data.frame(filename = character(0), type = character(0),
code = character(0), huni.chars = numeric (0))
file = "/home/chris/Github/Workshop_DGfS2022/Data/processed/unclassified_voy_0001.txt"
textfile <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0, nmax = 1000)
head(textfile)
filename <- basename(file)
subcorpus <- sub("_.*", "", filename)
subcorpus
?substring()
?gsub()
code <- grep("_.*_", filename)
code
filename
code <- grep("\_.*\_", filename)
code <- grep("\\_.*\\_", filename)
code
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = "\n" , skip = 0, nmax = 1000)
chars.df <- as.data.frame(table(chars))
chars.df
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
head(chars)
chars.df <- as.data.frame(table(chars))
chars.df
library(entropy)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
huni.chars
library(stringr)
library(entropy)
filename
id <- str_extract(filename, "_.*_")
id
id <- substr(str_extract(filename, "_.*_"), 2, 4)
id
entropy.df <- data.frame(filename = character(0), subcorpus = character(0),
id = character(0), huni.chars = numeric (0))
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# unigram entropy estimation
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
huni.chars
file.list <- list.files(path = "~/Github/Workshop_DGfS2022/Data/processed",
recursive = T, full.names = T)
head(file.list)
length(file.list)
counter = 0
# initialize data frame to append results to
entropy.df <- data.frame(filename = character(0), subcorpus = character(0),
id = character(0), huni.chars = numeric (0))
# start time
start_time <- Sys.time()
for (file in file.list) {
# loading textfile ("skip" specifies the number of lines to skip, whereas
# nmax gives the max number of lines to read.)
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# unigram entropy estimation
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
# append results to data frame
local.df <- data.frame(filename, subcorpus, id, huni.chars)
entropy.df <- rbind(entropy.df, local.df)
# counter
counter <- counter + 1
print(counter)
}
end_time <- Sys.time()
end_time - start_time
entropy.df
library(stringdist)
install.packages("stringdist")
library(stringr)
library(entropy)
library(stringdist)
char.bigrams <- qgrams(chars, q = 2)
char.bigrams
chars
chars.collapsed <- paste(chars, collapse = '')
chars.collapsed
char.bigrams <- qgrams(chars.collapsed, q = 2)
char.bigrams
char.bigrams <- qgrams(chars.collapsed, q = 3)
chars.bigrams
chars.bigrams <- qgrams(chars.collapsed, q = 3)
chars.bigrams
file = "/home/chris/Github/Workshop_DGfS2022/Data/processed/writing_ben_0001.txt"
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
id
chars.df
huni.chars
chars.collapsed <- paste(chars, collapse = '')
chars.collapsed
chars.bigrams <- qgrams(chars.collapsed, q = 3)
chars.bigrams
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 100)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
# calculate bigram entropy for characters
chars.collapsed <- paste(chars, collapse = '')
chars.bigrams <- qgrams(chars.collapsed, q = 2)
chars.bigrams
file = "/home/chris/Github/Workshop_DGfS2022/Data/processed/writing_eng_0001.txt"
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 100)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
# calculate bigram entropy for characters
chars.collapsed <- paste(chars, collapse = '')
chars.bigrams <- qgrams(chars.collapsed, q = 2)
chars.bigrams
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# calculate unigram entropy for characters
chars.df <- as.data.frame(table(chars))
# print(chars.df)
huni.chars <- entropy(chars.df$Freq, method = "ML", unit = "log2")
# calculate bigram entropy for characters
chars.collapsed <- paste(chars, collapse = '')
chars.bigrams <- qgrams(chars.collapsed, q = 2)
as.data.frame(chars.bigrams)
View(chars.bigrams)
chars.collapsed <- paste(chars, collapse = '')
chars.bigrams <- qgrams(chars.collapsed, q = 2)
chars.bigrams.df <- as.data.frame(chars.bigrams)
chars.bigrams.df$Freq
chars.bigrams.df <- as.data.frame(chars.bigrams)
View(chars.bigrams.df)
chars.bigrams
typeof(chars.bigrams)
chars.bigrams$V1
?qgrams
chars.collapsed <- paste(chars, collapse = '')
chars.bi.df <- as.data.frame(qgrams(chars.collapsed, q = 2))
chars.bi.df
chars.bi.df$V1
chars.bi.df[1]
chars.bi.df[1, ]
chars.bi.df[, 1]
chars.bi.df[V1]
chars.bi.df[,V1]
chars.bi.df[V1,]
table(chars)
chars.bi.df <- as.data.frame(qgrams(chars.collapsed, q = 2))
chars.bi.df
table(chars)$Freq
chars.uni.df <- as.data.frame(table(chars))
View(chars.uni.df)
chars.bi <- qgrams(chars.collapsed, q = 2)
chars.bi
typeof(chars.bi)
typeof(table(chars))
attributes(chars.bi)
chars.bi$dim
chars.bi$dimnames
install.packages("quanteda")
library(quanteda)
?char_ngrams
char_ngrams(chars.collapsed)
char_ngrams(chars.collapsed, concatenator = "")
char_ngrams(chars, concatenator = "")
char_ngrams(chars, n = 3, concatenator = "")
chars.bi.df <- as.data.frame(table(chars.bi))
chars.bi.df
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi
table(chars.bi)
as.data.frame(table(chars.bi))
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi.df <- as.data.frame(table(chars.bi))
head(chars.bi.df)
h.bi <- entropy(chars.bi.df$Freq, method = "ML", unit = "log2")
entropy.df <- data.frame(filename = character(0), subcorpus = character(0),
id = character(0), h.unigrams = numeric (0),
h.bigrams)
entropy.df <- data.frame(filename = character(0), subcorpus = character(0),
id = character(0), h.unigrams = numeric (0),
h.bigrams = numeric(0))
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# estimate entropy for character unigrams
chars.uni.df <- as.data.frame(table(chars))
h.unigrams <- entropy(chars.uni.df$Freq, method = "ML", unit = "log2")
# estimate entropy for character bigrams
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi.df <- as.data.frame(table(chars.bi))
h.bigrams <- entropy(chars.bi.df$Freq, method = "ML", unit = "lwog2")
# loading textfile ("skip" specifies the number of lines to skip, whereas
# nmax gives the max number of lines to read.)
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# estimate entropy for character unigrams
chars.uni.df <- as.data.frame(table(chars))
h.unigrams <- entropy(chars.uni.df$Freq, method = "ML", unit = "log2")
# estimate entropy for character bigrams
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi.df <- as.data.frame(table(chars.bi))
h.bigrams <- entropy(chars.bi.df$Freq, method = "ML", unit = "log2")
# append results to data frame
local.df <- data.frame(filename, subcorpus, id, h.unigrams, h.bigrams)
entropy.df <- rbind(entropy.df, local.df)
# counter
counter <- counter + 1
print(counter)
entropy.df
counter = 0
# initialize data frame to append results to
entropy.df <- data.frame(filename = character(0), subcorpus = character(0),
id = character(0), h.unigrams = numeric (0),
h.bigrams = numeric(0))
# start time
start_time <- Sys.time()
for (file in file.list) {
# loading textfile ("skip" specifies the number of lines to skip, whereas
# nmax gives the max number of lines to read.)
chars <- scan(file, what = "char", quote = "", comment.char = "",
encoding = "UTF-8", sep = " " , skip = 0, nmax = 1000)
# get filename
filename <- basename(file)
# get subcorpus category
subcorpus <- sub("_.*", "", filename)
# get three letter identifier from file name
id <- substr(str_extract(filename, "_.*_"), 2, 4)
# estimate entropy for character unigrams
chars.uni.df <- as.data.frame(table(chars))
h.unigrams <- entropy(chars.uni.df$Freq, method = "ML", unit = "log2")
# estimate entropy for character bigrams
chars.bi <- char_ngrams(chars, n = 2, concatenator = "")
chars.bi.df <- as.data.frame(table(chars.bi))
h.bigrams <- entropy(chars.bi.df$Freq, method = "ML", unit = "log2")
# append results to data frame
local.df <- data.frame(filename, subcorpus, id, h.unigrams, h.bigrams)
entropy.df <- rbind(entropy.df, local.df)
# counter
counter <- counter + 1
print(counter)
}
end_time <- Sys.time()
end_time - start_time
entropy.df
write.csv(entropy.df, "~/Github/Workshop_DGfS2022/Results/Application1/entropyEstimations.csv", row.names = F)
